\chapter*{Abstract}
As robots become increasingly integral to human life, the imperative emerges for them to autonomously explore and construct models of their bodies. Robots should take cues from human capabilities, aspiring to build and utilize their body schema for advanced locomotion, finer manipulation, and adaptive interactions. Thus, a crucial foundation lies in seamlessly integrating the body schema to elevate learning, motor control, coordination, and spatial awareness. Furthermore, future robots should become self-sufficient entities that conduct monitoring, calibration, and adaptation exclusively through onboard sensing modalities. Standardizing constant self-monitoring nurtures spatial awareness and facilitates rapid error detection and correction. A profound understanding of their body structure will undoubtedly lead to enhanced, safe, and energy-aware interactions. However, current robot learning approaches encounter limitations,  such as suboptimal generalization and sample efficiency, exhibiting a need for more structural knowledge. Versatile methods, like neural networks, confront challenges related to data and topology, confining learning to specific regions. On the other hand, learning robot physical attributes still rely on a presumed knowledge of the mechanical topology, often involving calibration and offline identification in controlled environments with a persistent reliance on external measurements, such as vision and motion-capturing systems. The research landscape generally reveals the lack of a unified framework that enables robots to build representations of their body schema to achieve improved body awareness and interaction capabilities. This study addresses these challenges by consolidating necessary and sufficient proprioceptive signal quantities, enabling robots to autonomously acquire knowledge about their body structure without relying on exteroceptive off-body sensors. It introduces an approach that reformulates robot kinematic calibration and system identification as a modular computational graph amenable to machine learning. This abstracted architecture, applied in online learning phases, seamlessly merges proprioceptive signals with first-order principles, extracting fundamental features of the robot body schema. Characterizing morphological properties of tree-like structures, the study infers mechanical topology through information-theoretic measures, validating and applying it independently of off-robot calibration. The research extends its scope by complementing the robot body schema by instantiating inertial properties, ensuring online learning and physical feasibility. Ultimately, this work challenges the uncritical application of end-to-end learning in physical systems, urging a reevaluation of its limitations when excluding principled knowledge. It underscores opportunities for machine learning frameworks in embodied systems, emphasizing the untapped potential of synergizing structural knowledge with data-driven methods. This study catalyzes future research in an incipient field that underscores building and maintaining a body schema by demonstrating that fundamental properties of a robot's morphology can be deduced from proprioceptive signals. Its implications are far-reaching, addressing the needs of conventional and dynamic robotic structures with diverse sensory modalities that require a more profound sense of self.
%In the realm of robotics, the seamless integration of the body schema emerges as a foundational pillar, facilitating learning, motor control, coordination, and advanced spatial awareness for future robots. As robots become integral to diverse aspects of human life, autonomous self-discovery of their body schema becomes imperative. Inspired by human capabilities, future robots are envisioned to skillfully employ their body schema for advanced locomotion, motion planning, precise grasping, intricate object manipulation, and adaptive interactions with other agents. Constant self-monitoring of the sensorimotor state and internal body models becomes the norm, enabling instantaneous error detection and correction, fostering spatial awareness and advanced interaction capabilities. Robots are anticipated to be self-sufficient entities, performing monitoring, calibration, and adaptation of their body representation solely through onboard sensing capabilities, encompassing somatosensation and vision. Understanding their own body structure enhances interactions with other robots and humans, allowing adjustments for safety and optimizing energy consumption for energy-aware robotics. However, challenges persist in current robot learning approaches, including limitations in generalization capabilities, reliance on external measurements, and gaps in understanding object handling and mechanical topology. Addressing these challenges, the research consolidates proprioceptive signals, freeing robots from dependency on external sensors. Introducing a computational graph for robot calibration and system identification, the study abstracts this into a pipeline of online learning phases, merging proprioceptive signals with first-order principles to extract fundamental features of the robot body schema. The research characterizes morphological properties, infers mechanical topology, and instantiates inertial properties, challenging end-to-end learning approaches and emphasizing the need for a synergistic integration of existing structural knowledge with data-driven methods. The impact of this work extends beyond theoretical realms, demonstrating that a robot's body schema can be deduced through a fundamental set of proprioceptive signals. As future robots are anticipated to feature diverse on-board sensing modalities, the findings serve as a catalyst for research into their integration, coupled with online learning of body properties, promising refined body models and heightened autonomy. This study significantly contributes to the emerging research area, emphasizing the importance of building and maintaining a body schema for embodied systems, spanning conventional structures to those with dynamic morphologies and multimodal sensory modalities.

%In the rapidly advancing field of robotics, the seamless integration of the body schema emerges as a cornerstone for the future development of robots, unlocking a myriad of capabilities including learning, motor control, coordination, and advanced spatial awareness. As robots transition from mere tools to integral components of human life, the imperative of autonomous self-discovery of their body schema becomes evident. Taking inspiration from human capabilities, the vision for future robots extends beyond mere functionality to encompass the skillful deployment of their body schema for advanced locomotion, precise grasping, intricate object manipulation, and adaptive interaction with other agents. A paradigm shift is observed in the constant self-monitoring of sensorimotor states and internal body models, becoming a norm for instantaneous error detection and correction. This practice, rooted in adaptability, facilitates the development of spatial awareness, enabling rapid planning and deployment of contingent motion strategies for advanced interaction capabilities with the environment. Robots are envisioned to be self-sufficient entities capable of monitoring, calibrating, and adapting their body representation through onboard sensing capabilities, incorporating somatosensation (proprioception and touch) and vision as fundamental modalities. Understanding their own body structure not only enhances robots' interactions with other robots and humans by adjusting movements for safety but also enables them to optimize energy consumption based on physical properties, contributing to the realm of energy-aware robotics. However, this vision faces several challenges inherent in current robot learning approaches, ranging from limitations in generalization capabilities to a heavy reliance on external measurements such as vision and motion-capturing systems for calibration. In response to these challenges, this research makes a significant contribution by consolidating proprioceptive signals, liberating robots from their dependency on exteroceptive off-body sensors. The introduction of a computational graph for robot kinematic calibration and system identification presents a novel approach, abstracted into a pipeline of online learning phases. This transformative architecture integrates streams of proprioceptive signals with first-order principles, facilitating the extraction of fundamental features of the robot body schema. Furthermore, the study characterizes essential morphological properties and infers mechanical topology using model-free information-theoretic measures, validating and employing this topology for the kinematic description of the robot's body without external calibration devices. The instantiation of inertial properties, governed by the Riemannian manifold of symmetric positive definite matrices, is introduced for online learning while ensuring physical feasibility. This holistic integration challenges the application of end-to-end learning approaches to physical systems, emphasizing the need for a synergistic integration of existing structural knowledge with data-driven methods. The impact of this work extends beyond theoretical realms, demonstrating that a robot's body schema can be deduced through a fundamental set of proprioceptive signals. As future robots are anticipated to feature diverse on-board sensing modalities, the findings serve as a catalyst for research into the integration of these modalities, coupled with online learning of body properties. This integration holds the promise of refining and adapting body models, ultimately empowering robots with heightened autonomy. In conclusion, this study significantly contributes to the emerging research area emphasizing the importance of building and maintaining a body schema as a crucial capability for embodied systems. It spans the spectrum from robots with conventional structures to those with dynamic morphologies and multimodal sensory modalities, paving the way for a future where robots seamlessly integrate and evolve their sense of self, recognizing and utilizing the affordances inherent in their bodies.



%In the quest for advancing robotics, the integration of the body schema emerges as a foundational pillar, fostering enhanced motor control, coordination, and spatial awareness. Inspired by human capabilities, future robots aim to adeptly employ the body schema for intricate object manipulation, adaptive responses, and instantaneous error correction. As robots become pervasive in human life, the autonomous development of body models becomes imperative, influencing real-time self-monitoring and optimizing energy consumption. However, challenges persist in learning a robot's physical attributes, calibration routines, and offline identification methods, particularly for floating base robots.
%
%This thesis tackles these challenges and makes significant contributions. It identifies proprioceptive signals for robot self-discovery and explores the influence of embodiment and first-order principles in shaping network topologies. The restructuring of kinematic calibration and parametric system identification processes for stationary-base robots into an online learning scenario, utilizing proprioception and kinematic/dynamic principles, marks a paradigm shift.
%
%The thesis unfolds in four interconnected parts. The first introduces the fundamentals of robotic calibration, system identification, and body schema concepts. It delves into different meanings of the body schema and outlines learning stages for characterizing the robotic body schema from an engineering perspective. In the second part, the concept of embodiment and its significance in finding the robot structure is presented. In particular, mutual information is proposed as a tool to unveil the mechanical topology based on proprioceptive signals. The third section deals with the characterization of the kinematic structure extending exteroception-based kinematic calibration methods with proprioception-based online learning. Crucially, the discussion departs from the assumption of a known mechanical topology, elaborating on how mutual information and basic differential kinematic laws characterize the robot's joint axes. The fourth part 
%delves into established methods for robot inertial parameter identification and proposes gradient-based online learning methods. Exploits the property that inertial parameters lie on the manifold of symmetric positive definite matrices.
%
%This work demonstrates that, with the proper set of proprioceptive measurements, the body schema's properties can be learned. It breaks constraints of laboratory-based robotic system identification, showing that mutual information evaluates nonlinear relationships among sensorimotor signals, linked to the embodiment of the robot. In essence, this thesis paves the way for advanced robotic functionality, adaptability, and autonomy.

%Robots are becoming more and more commodity in our society.
%Industry has long been a place for robots, but now also healthcare, logistics, and the domestic sector are starting to take advantage of such flexible automation solutions.
%The most relevant drivers for this development are the demographic change and labor shortage.
%In order to meet the upcoming requirements technology jumps are necessary that pave the way for next-generation tactile robots.
%Future Workplaces and factories will rely on the versatility and manipulation capabilities of tactile robots to automate highly dynamic manufacturing processes while keeping the energy demand low.
%The robots will generate solutions to problems on-the-fly without the need for manual programming, and learn them completely autonomously.
%They will become intelligent tools in autonomous, modular factories, assistants in households, and embodiments for telepresence applications.
%Besides interaction and mobility, manipulation capabilities are key to progress further in this direction.
%
%Vast progress in robotic manipulation research has already been made toward this vision, especially in the last decade, and the results, such as novel control methodologies, motion planning, and perception are beginning to merge into the industrial domain.
%As of today there already exist application fields such as testing, inspection and machine tending that make use of advanced pre-programmed robot skills.
%However, considering more difficult manipulation processes, there is a two-part challenge. First, there is a missing constructive link between process descriptions and tactile skill models. Second, learning such models for challenging tactile processes is difficult and currently not even the most powerful (traditional) end-to-end frameworks are capable of generating reliable manipulation skill solutions, let alone achieve transfer between different problems.
%
%The main contribution of this thesis is an autonomous synthesis framework that connects formal process definitions provided by process experts with compatible tactile skill models.
%The connection between these endpoints is proposed to be a tactile manipulation skill taxonomy that determines a unique solution skill for a given process.
%The tactile skill is then formulated as a learning problem that can be solved with a sample-efficient learning architecture.
%This divide and conquer approach can be scaled indefinitely in terms of numbers of skills and processes and can also be connected to automatic process planning systems. It may thus allow for solving complex tasks without the need for expert programming.
%The resulting versatility in terms of manipulation process solutions makes this concept a first step toward an ever increasing curriculum for robots that, similar to established curricula for (human) trainees in industrial fields, could provide a framework for the acquisition of all relevant manipulation skills for robots.
%
%This thesis provides the theoretical foundations for tactile skills, their synthesis, learning and planning capabilities.
%It describes the implementation of the foundations and a number of validation cases.
%Extensive experimental work is presented that demonstrates the manipulation framework's capabilities.
%Exhaustive verification experiments validate the approach for a meaningful number of skills, showcasing high robustness and performance, which are fundamental requirements for industrial applications.
%The learning performance of the proposed architecture and synthesis pipeline is analyzed for state-of-the-art machine learning algorithms.
%The overall system shows superior learning performance and efficiency when compared against bleeding-edge end-to-end approaches.
%In a large experimental campaign, even a systematic transfer learning effect between different challenging physical manipulation skill instances was observed. This allows to learn large number of skills by systematically exploiting their similarity.
%The performance of the optimized skills and the learning performance are directly compared to human capabilities.
%The results show that for some skills human-level performance can already be achieved.
%Finally, a collaborative assembly planning problem for industrial mechatronics systems with tight tolerances and multi-dimensional insertion processes showcases the planning capabilities of the framework.
%With the developed framework it finally is possible to automate robot programming even for complex manipulation processes without the need for robot expert knowledge.
%
%The results of this work have impacted further research efforts in control, learning, telepresence, and motion planning, and have even opened up an entirely new field, namely dentronics. Furthermore, it has influenced various projects, publications and products.
%To the best of the author's knowledge, this thesis is the first that enables non-experts to solve complex manipulation problems on an industrial level through an automatic skill synthesis and learning approach with low energy demand and only restricted computational resources.
